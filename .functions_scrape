#!/bin/bash

function scrape_guardian() {
	if [ -z "$(which scrape)" ]; then
		echo "scrape has not been installed"
		return
	fi
	if [ -z "$(which gum)" ]; then
		echo "gum has not been installed"
		return
	fi
  if [ -z "$(which glow)" ]; then
    echo "glow has not been installed"
    return
  fi

  local section_urls selected_url selected_markdown_link article_url

  ## array of urls
  section_urls=(
    "https://www.theguardian.com/us-news"
    "https://www.theguardian.com/uk-news"
    "https://www.theguardian.com/international"
    "https://www.theguardian.com/world"
    "https://www.theguardian.com/business"
    "https://www.theguardian.com/uk/technology"
    "https://www.theguardian.com/science"
    "https://www.theguardian.com/football"
    "https://www.theguardian.com/world/asia"
  )

  selected_url=$(printf "%s\n" "${section_urls[@]}" | gum filter --limit=1)
  if [ -z "$selected_url" ]; then
    echo "No section URL selected."
    return
  fi

  selected_markdown_link=$(scrape links --source guardian --url "$selected_url" | gum filter --limit=1)
  if [ -z "$selected_markdown_link" ]; then
    echo "No article selected."
    return
  fi

  article_url=$(echo "$selected_markdown_link" | awk -F'(' '{print $2}' | awk -F')' '{print $1}')
  scrape article --source guardian --url "$article_url" | glow
}

function scrape_guardian_to_epub() {
  if [ -z "$(which scrape)" ]; then
    echo "scrape has not been installed"
    return
  fi
  if [ -z "$(which gum)" ]; then
    echo "gum has not been installed"
    return
  fi
  if [ -z "$(which ebook-convert)" ]; then
    echo "ebook-convert has not been installed"
    return
  fi

  local section_urls selected_url selected_markdown_link article_url markdown_file_directory

  ## array of urls
  section_urls=(
    "https://www.theguardian.com/us-news"
    "https://www.theguardian.com/uk-news"
    "https://www.theguardian.com/international"
    "https://www.theguardian.com/world"
    "https://www.theguardian.com/business"
    "https://www.theguardian.com/uk/technology"
    "https://www.theguardian.com/science"
    "https://www.theguardian.com/football"
    "https://www.theguardian.com/world/asia"
  )

  selected_url=$(printf "%s\n" "${section_urls[@]}" | gum filter --limit=1)
  if [ -z "$selected_url" ]; then
    echo "No section URL selected."
    return
  fi

  selected_markdown_link=$(scrape links --source guardian --url "$selected_url" | gum filter --limit=1)
  if [ -z "$selected_markdown_link" ]; then
    echo "No article selected."
    return
  fi

  article_url=$(echo "$selected_markdown_link" | awk -F'(' '{print $2}' | awk -F')' '{print $1}')
  markdown_file_directory=$(mktemp -d)
  scrape article --source guardian --url "$article_url" > "$markdown_file_directory/temp.md"
  ebook-convert "$markdown_file_directory/temp.md" "${article_url##*/}.epub" --title "${article_url##*/}" --authors "The Guardian" --language "en" --no-default-epub-cover
}

function scrape_microsoft_learn_to_epub() {
  if [ -z "$(which scrape)" ]; then
    echo "scrape has not been installed"
    return
  fi
  if [ -z "$(which ebook-convert)" ]; then
    echo "ebook-convert has not been installed"
    return
  fi

  if [ -z "$1" ]; then
    echo "Missing parameters. Usage: scrape_microsoft_learn_to_epub <url>"
    return
  fi

  local markdown_file_directory

  markdown_file_directory=$(mktemp -d)
  scrape article --source microsoft --url "$1" > "$markdown_file_directory/temp.md"
  ebook-convert "$markdown_file_directory/temp.md" "${1##*/}.epub" --title "${1##*/}" --authors "microsoft Learn" --language "en" --no-default-epub-cover
}

function scrape_tofugu_to_epub() {
  if [ -z "$(which scrape)" ]; then
    echo "scrape has not been installed"
    return
  fi
  if [ -z "$(which markdown-to-epub)" ]; then
    echo "markdown-to-epub has not been installed"
    return
  fi

  if [ -z "$1" ]; then
    echo "Missing parameters. Usage: scrape_tofugu_to_epub <url>"
    return
  fi

  local markdown_file_directory title output_filename

  title=$(scrape title --source tofugu --url "$1")
  output_filename="$(scrape filename --source tofugu --url "$1").epub"
  markdown_file_directory=$(mktemp -d)

  scrape article --source tofugu --url "$1" > "$markdown_file_directory/temp.md"

  markdown-to-epub generate -l ja -i "${markdown_file_directory}/temp.md" -t "$title" -a "tofugu.com" -o "${output_filename}"
}
